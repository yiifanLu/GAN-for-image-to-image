20-05-28 17:00:28.907 - INFO:   name: diffuse_new
  use_tb_logger: True
  model: GIGAN
  image_type: png
  scale: 4
  gpu_ids: [0]
  datasets:[
    train:[
      name: train_Tencent_deep_inverse_rendering
      mode: Tencent_deep_inverse_rendering
      feature: ['albedo', 'normal', 'depth']
      dataroot_GT: E:/dataset/train
      dataroot_NOISY: E:/dataset/train
      subset_file: None
      use_shuffle: True
      n_workers: 0
      batch_size: 4
      GT_size: 128
      use_flip: True
      use_rot: True
      phase: train
      scale: 4
    ]
    val:[
      name: val_Tencent_deep_inverse_rendering
      mode: Tencent_deep_inverse_rendering
      dataroot_GT: E:/dataset/train
      dataroot_NOISY: E:/dataset/train
      phase: val
      scale: 4
    ]
  ]
  path:[
    root: D:/chengdu/Tencent/codes/pytorch
    val_root: D:/chengdu/Tencent/codes/pytorch
    experiments_root: D:/chengdu/Tencent/codes/pytorch\experiments\diffuse_new
    models: D:/chengdu/Tencent/codes/pytorch\experiments\diffuse_new\models
    training_state: D:/chengdu/Tencent/codes/pytorch\experiments\diffuse_new\training_state
    log: D:/chengdu/Tencent/codes/pytorch\experiments\diffuse_new
    val_images: D:/chengdu/Tencent/codes/pytorch\val_images
  ]
  network_G:[
    which_model_G: U-net
    scale: 4
  ]
  network_D:[
    which_model_D: PatchGAN
    norm_type: batch
    act_type: leakyrelu
    mode: CNA
    nf: 64
    in_nc: 3
  ]
  train:[
    lr_G: 0.0002
    weight_decay_G: 0
    beta1_G: 0.5
    lr_D: 0.0002
    weight_decay_D: 0
    beta1_D: 0.5
    lr_scheme: MultiStepLR
    lr_steps: [50000, 100000, 150000, 200000]
    lr_gamma: 0.5
    pixel_criterion: l1
    pixel_weight: 100
    feature_criterion: l1
    feature_weight: 0
    gan_type: wgan-gp
    gan_weight: 1
    D_update_ratio: 1
    D_init_iters: 0
    gp_weigth: 10
    manual_seed: 0
    niter: 600000.0
    val_freq: 5000.0
  ]
  logger:[
    print_freq: 200
    save_checkpoint_freq: 5000.0
  ]
  is_train: True

20-05-28 17:00:29.417 - INFO: Random seed: 0
20-05-28 17:00:29.518 - INFO: Dataset [InverseRenderingDataset - train_Tencent_deep_inverse_rendering] is created.
20-05-28 17:00:29.519 - INFO: Number of train images: 489, iters: 123
20-05-28 17:00:29.520 - INFO: Total epochs needed: 4879 for iters 600,000
20-05-28 17:00:29.530 - INFO: Dataset [InverseRenderingDataset - val_Tencent_deep_inverse_rendering] is created.
20-05-28 17:00:29.531 - INFO: Number of val images in [val_Tencent_deep_inverse_rendering]: 55
20-05-28 17:00:30.600 - INFO: Initialization method [normal]
20-05-28 17:00:39.137 - INFO: Initialization method [normal]
20-05-28 17:00:39.178 - INFO: Network G structure: DataParallel - UNET_Network, with parameters: 54,423,171
20-05-28 17:00:39.180 - INFO: UNET_Network(
  (model): UnetSkipConnectionBlock(
    (model): Sequential(
      (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (1): UnetSkipConnectionBlock(
        (model): Sequential(
          (0): LeakyReLU(negative_slope=0.2, inplace=True)
          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): UnetSkipConnectionBlock(
            (model): Sequential(
              (0): LeakyReLU(negative_slope=0.2, inplace=True)
              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (3): UnetSkipConnectionBlock(
                (model): Sequential(
                  (0): LeakyReLU(negative_slope=0.2, inplace=True)
                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                  (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (3): UnetSkipConnectionBlock(
                    (model): Sequential(
                      (0): LeakyReLU(negative_slope=0.2, inplace=True)
                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      (3): UnetSkipConnectionBlock(
                        (model): Sequential(
                          (0): LeakyReLU(negative_slope=0.2, inplace=True)
                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                          (3): UnetSkipConnectionBlock(
                            (model): Sequential(
                              (0): LeakyReLU(negative_slope=0.2, inplace=True)
                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                              (3): UnetSkipConnectionBlock(
                                (model): Sequential(
                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)
                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                                  (2): ReLU(inplace=True)
                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                                  (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                )
                              )
                              (4): ReLU(inplace=True)
                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                              (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                              (7): Dropout(p=0.5, inplace=False)
                            )
                          )
                          (4): ReLU(inplace=True)
                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                          (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                          (7): Dropout(p=0.5, inplace=False)
                        )
                      )
                      (4): ReLU(inplace=True)
                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      (7): Dropout(p=0.5, inplace=False)
                    )
                  )
                  (4): ReLU(inplace=True)
                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
                  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (4): ReLU(inplace=True)
              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (4): ReLU(inplace=True)
          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): ReLU(inplace=True)
      (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (4): Tanh()
    )
  )
)
20-05-28 17:00:39.181 - INFO: Network D structure: DataParallel - discriminator_patch, with parameters: 2,777,921
20-05-28 17:00:39.182 - INFO: discriminator_patch(
  (model): Sequential(
    (0): Conv2d(15, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
  )
)
20-05-28 17:00:39.183 - INFO: Model [GIGAN_Model] is created.
20-05-28 17:00:39.184 - INFO: Start training from epoch: 0, iter: 0
